import pandas as pd
import pandas_ta as ta
import numpy as np



def TechnicalIndicators(data):
    # Feature Engineering (Adding Technical Indicators)
    # Technical_Indicators= ['rsi', 'macd', 'bollinger_width', 'atr', 'price_change_pct', 'volume_change_pct']
    data['rsi'] = ta.momentum.RSIIndicator(data['close']).rsi()
    data['macd'] = ta.trend.MACD(data['close']).macd()
    data['bollinger_width'] = ta.volatility.BollingerBands(data['close']).bollinger_wband()
    data['atr'] = ta.volatility.AverageTrueRange(data['high'], data['low'], data['close']).average_true_range()
    
    # Momentum-Based Features
    data['price_change_pct'] = data['close'].pct_change() * 100
    data['volume_change_pct'] = data['volume'].pct_change() * 100
    
    data.fillna(0, inplace=True)  # Fill NaNs caused by indicators

    # Support_Resistance_Levels= ['dist_to_resistance', 'rolling_min']
    # Identify Support and Resistance Levels
    window=20
    data['rolling_max'] = data['high'].rolling(window=window, min_periods=1).max()
    data['rolling_min'] = data['low'].rolling(window=window, min_periods=1).min()
    
    # Calculate Distance to Nearest S&R Level
    data['dist_to_resistance'] = data['rolling_max'] - data['close']
    data['dist_to_support'] = data['close'] - data['rolling_min']
    
    data.drop(columns=['rolling_max', 'rolling_min'], inplace=True)  # Clean up temp columns





   
    # profit_loss_pct_lagged= [profit_loss_pct_lagged']
    # Add Profitability Feature (Lagged to prevent data leakage)
    ################### need to think Lagged #####################
    future_period=5
    data['profit_loss_pct'] = (data['close'].shift(-future_period) - data['close']) / data['close'] * 100
    data['profit_loss_pct_lagged'] = data['profit_loss_pct'].shift(future_period)  # Shift backward to avoid data leakage
    data.drop(columns=['profit_loss_pct'], inplace=True)  # Remove future-based feature
    data.fillna(0, inplace=True)
   

   




# Create Buy/Sell/Hold Labels Dynamically
    future_period=5, atr_multiplier=1.5
    labels = []
    rewards = []
    for i in range(len(data) - future_period):
        future_close = data.iloc[i + future_period]['close']
        atr_threshold = data.iloc[i]['atr'] * atr_multiplier
        price_change = future_close - data.iloc[i]['close']
        profit_loss = data.iloc[i]['profit_loss_pct_lagged']
        
        if price_change > atr_threshold:
            labels.append(1)  # Buy
            rewards.append(1 if profit_loss > 0 else -1)  # Reward/Penalty
        elif price_change < -atr_threshold:
            labels.append(-1)  # Sell
            rewards.append(1 if profit_loss > 0 else -1)
        else:
            labels.append(0)  # Hold
            rewards.append(0.1)  # Small reward for avoiding unnecessary trades
    
    labels.extend([0] * future_period)  # Padding for last rows
    rewards.extend([0] * future_period)
    data['label'] = labels
    data['reward'] = rewards
  
   

    



    data.to_csv("./Functions_V2/data_tech.csv", index=False)
    # Drop NaN values generated by indicator calculations
    data.dropna(inplace=True)

    return data
















# import pandas as pd
# import pandas_ta as ta
# import numpy as np



# def TechnicalIndicators(data):
#     # Simple Moving Average (SMA)
#     data['SMA'] = data['Close'].rolling(window=14).mean()




#     # Moving Average Convergence Divergence (MACD)
#     data['MACD'] = data['Close'].ewm(span=12, adjust=False).mean() - data['Close'].ewm(span=26, adjust=False).mean()




#     # Relative Strength Index (RSI)
#     delta = data['Close'].diff(1)
#     gain = delta.where(delta > 0, 0)
#     loss = -delta.where(delta < 0, 0)
#     avg_gain = gain.rolling(window=14).mean()
#     avg_loss = loss.rolling(window=14).mean()
#     rs = avg_gain / avg_loss
#     data['RSI'] = 100 - (100 / (1 + rs))

#     # Calculate RSI for different periods
#     data['RSI_14'] = ta.rsi(close=data['Close'], length=14)  # Default 14-period
#     data['RSI_7'] = ta.rsi(close=data['Close'], length=7)    # Shorter-term RSI
#     data['RSI_28'] = ta.rsi(close=data['Close'], length=28)  # Longer-term RSI




#     #Average True Range (ATR)
#     data['ATR'] = ta.atr(high=data['High'], low=data['Low'], close=data['Close'], length=14)  # Default 14-period




#     #Short-Term and Long-Term Volatility Using Standard Deviation
#     # Calculate short-term volatility (5 periods)
#     data['Short_Term_SD'] = data['Close'].rolling(window=5).std()
#     # Calculate long-term volatility (20 periods)
#     data['Long_Term_SD'] = data['Close'].rolling(window=20).std()




#     # Calculate %K
#     data['Lowest_Low'] = data['Low'].rolling(window=14).min()
#     data['Highest_High'] = data['High'].rolling(window=14).max()
#     data['%K'] = ((data['Close'] - data['Lowest_Low']) / (data['Highest_High'] - data['Lowest_Low'])) * 100

#     # Calculate %D (3-period SMA of %K)
#     data['%D'] = data['%K'].rolling(window=3).mean()


#     # Calculate Williams %R
#     data['Williams_%R'] = ((data['Highest_High'] - data['Close']) / (data['Highest_High'] - data['Lowest_Low'])) * -100





#     # Calculate Parabolic SAR
#     psar_data=ta.psar(high=data['High'], low=data['Low'], close=data['Close'], af=0.02, max_af=0.2)
   
#     data['Parabolic_SAR'] = psar_data['PSARl_0.02_0.2']
#     data['PSAR_Signal'] = psar_data['PSARs_0.02_0.2']
#     data['PSAR_Reversal'] = psar_data['PSARr_0.02_0.2']


#     # Calculate Bollinger Bands
#     bbands=ta.bbands(close=data['Close'], length=20, std=2)
#     data['BB_Middle']= bbands['BBM_20_2.0']
#     data['BB_Upper']=bbands['BBU_20_2.0']
#     data['BB_Lower']= bbands['BBL_20_2.0']
#     data['BB_Distance'] = (data['Close'] - data['BB_Middle']) / (data['BB_Upper'] - data['BB_Lower'])
#     data['BB_Bandwidth'] = data['BB_Upper'] - data['BB_Lower']





#     # Calculate On-Balance Volume
#     data['OBV'] = (np.sign(data['Close'].diff()) * data['Volume']).fillna(0).cumsum()

#     # Calculate VWAP
#     data['Typical_Price'] = (data['High'] + data['Low'] + data['Close']) / 3
#     data['Cumulative_TPV'] = (data['Typical_Price'] * data['Volume']).cumsum()
#     data['Cumulative_Volume'] = data['Volume'].cumsum()
#     data['VWAP'] = data['Cumulative_TPV'] / data['Cumulative_Volume']
#     # Drop intermediate columns
#     data.drop(['Typical_Price', 'Cumulative_TPV', 'Cumulative_Volume'], axis=1, inplace=True)




#     # Add Lagged Features (Lag-1, Lag-2, etc.)
#     lags = 3  # Number of lags
#     for col in ['Open', 'High', 'Low', 'Close', 'Volume']:
#         for lag in range(1, lags + 1):
#             data[f'{col}_Lag_{lag}'] = data[col].shift(lag)

    

   


    
#     data['Timestamp'] = pd.to_datetime(data['Timestamp'])

#     # Extract hour, minute, day of week, etc.
#     data['Hour'] = data['Timestamp'].dt.hour
#     data['Minute'] = data['Timestamp'].dt.minute
#     data['Second'] = data['Timestamp'].dt.second
#     data['Day_of_Week'] = data['Timestamp'].dt.dayofweek  # Monday=0, Sunday=6
#     data['Day_of_Year'] = data['Timestamp'].dt.dayofyear
#     data['Time_in_Seconds'] = data['Hour'] * 3600 + data['Minute'] * 60 + data['Second']

#     # Daily seasonality (hourly cycles)
#     data['Sin_Hour'] = np.sin(2 * np.pi * data['Hour'] / 24)
#     data['Cos_Hour'] = np.cos(2 * np.pi * data['Hour'] / 24)

#     # Weekly seasonality (day of the week)
#     data['Sin_Day_of_Week'] = np.sin(2 * np.pi * data['Day_of_Week'] / 7)
#     data['Cos_Day_of_Week'] = np.cos(2 * np.pi * data['Day_of_Week'] / 7)

#     # Yearly seasonality (day of the year)
#     data['Sin_Day_of_Year'] = np.sin(2 * np.pi * data['Day_of_Year'] / 365)
#     data['Cos_Day_of_Year'] = np.cos(2 * np.pi * data['Day_of_Year'] / 365)


   

    




#     data['Parabolic_SAR'].fillna(method='ffill', inplace=True)
#     data['PSAR_Signal'].fillna(0, inplace=True)  # Replace NaN with 0
#     data.to_csv("./Functions_V2/data_tech.csv", index=False)
#     # Drop NaN values generated by indicator calculations
#     data.dropna(inplace=True)

#     return data



